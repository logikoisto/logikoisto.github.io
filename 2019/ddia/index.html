<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="觉有情">
  
  
  
  <link rel="prev" href="https://logikoisto.github.io/2019/linked_list/" />
  <link rel="next" href="https://logikoisto.github.io/2019/useless/" />
  <link rel="canonical" href="https://logikoisto.github.io/2019/ddia/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           数据密集型应用系统设计-读后感 | 孙权
       
  </title>
  <meta name="title" content="数据密集型应用系统设计-读后感 | 孙权">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://logikoisto.github.io/"
    },
    "articleSection" : "posts",
    "name" : "数据密集型应用系统设计-读后感",
    "headline" : "数据密集型应用系统设计-读后感",
    "description" : "本文主要总结,DDIA这本书中的系统设计之精髓,全是是我看完书之后凭记忆进行的总结,若有不恰当之处,欢迎指出",
    "inLanguage" : "en-us",
    "author" : "觉有情",
    "creator" : "觉有情",
    "publisher": "觉有情",
    "accountablePerson" : "觉有情",
    "copyrightHolder" : "觉有情",
    "copyrightYear" : "2019",
    "datePublished": "2019-08-10 00:00:00 &#43;0000 UTC",
    "dateModified" : "2019-08-10 00:00:00 &#43;0000 UTC",
    "url" : "https://logikoisto.github.io/2019/ddia/",
    "wordCount" : "141",
    "keywords" : [ "架构设计", "孙权"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://logikoisto.github.io/">孙权</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://logikoisto.github.io/">孙权</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">数据密集型应用系统设计-读后感</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://logikoisto.github.io/" rel="author">觉有情</a> with ♥ 
                <span class="post-time">
                on <time datetime=2019-08-10 itemprop="datePublished">August 10, 2019</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://logikoisto.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"> 读书笔记 </a>
                        
                </span>
        </div>
    </header>
    <div class="post-content">
        

        

        
        
     
          
          
          

          
          
          

          

<h1 id="存储与检索的基本设计理念">存储与检索的基本设计理念</h1>

<p>本篇主要讲述我对DDIA这本书的个人理解,帮助读者更快的了解DDIA并以一种思维贯穿始终,以便可以更好的应用在实际问题当中。数据密集型系统是指,通过IO将数据进行处理的系统,而用于解决将数据进行计算分析的系统则称之为计算密集型系统,本篇主要讨论数据密集型系统</p>

<h1 id="数据系统的目标">数据系统的目标</h1>

<p>数据密集型系统的主要指标有三个,可扩展性,可靠性,可维护性</p>

<h3 id="可扩展性">可扩展性</h3>

<p>可扩展性强调数据系统可以通过增加单台机器的性能或者机器的数量来使系统的负载线性增长的一种表现。通过增加单台机器的内存,磁盘,cpu核数或者处理能力,来垂直的增加系统的负载能力可以称之为垂直扩展,而通过增加同规格机器的数量来使负载增强的方式可以称之为水平扩展。对于计算机硬件来说,单台机器的性能总是昂贵的,所以水平扩展的方式虽然在实现上更加复杂,但因其成本很低,故而被广泛采用,随着数据规模的增加,成本的考量将成为重中之重。</p>

<h3 id="如何描述一个系统的扩展性">如何描述一个系统的扩展性?</h3>

<p>对于一个通常的系统,我们主要考察三点,吞吐率,响应时间以及失败率.吞吐率强调在单位之间内处理请求的数量。他强调了一个数据系统能够处理多大的数据规模,响应时间指的是处理一次请求需要用到的时间。二者是相辅相成的,不能孤立存在。因为对于实际中的系统,所有的指标都应该在相同数据规模的前提下,假设一个系统在一秒中接受到了10万个请求,其表示在一瞬间有10万个请求到达服务器,那么其吞吐率就是10w/s;但是每个请求却用了10秒中来处理,其响应时间就是10s/sec而在这10秒中的时间窗口中又有一半的请求失败,其失败率为50%。所以三个指标必须在一定数据规模的前提下同时限定才能描述一个数据系统的扩展性。对于三个参数指标,其精准的测量一般是没有意义的,而是采用统计的方式进行描述,并且坚决鄙视平均值,而是使用百分位数来描述,即在一定吞吐量下,百分之多少的请求数内,其响应时间及其失败率是有效的。例如,10wQPS(吞吐率)下,百分之九十九的请求其响应时间最慢是二十毫秒,其失败率为千分之一。</p>

<h3 id="可靠性">可靠性</h3>

<p>数据系统需要长时间的运行,理想的期望是永不间断,然而总是会有各种问题导致其失效,某种异常没有处理,导致系统崩溃或者负载占用资源过高(例如OOM)被系统kill掉。一旦系统无法对外工作,我们就说其已经失效。如何描述一个系统的可靠性呢?通常我们在一个数据系统在一年中,累积失效的时间来衡量,例如: 系统可靠性为99.999%,即在系统运行的一年中累积只有0.001%的时间处于不可用状态,也就是大约累积5分钟的失效时间。</p>

<h3 id="可维护性">可维护性</h3>

<p>可维护性的范围有些广泛,数据系统本质上是一种超大型的复杂软件,软件是具有生命周期的,其需求与功能都是在不断的变化的,我们需要在一定程度上面向未来的需求设计软件。以便可以更简单的部署,运维,扩展与修改系统。同时打造人类可理解的系统也尤为重要,说到底,软件是服务于人的,必将由人来负责,因此系统行为的可观测性与可理解性非常重要,对于静态的代码,可读性非常关键,这直接关心到一个软件系统的生命力,程序员对于生涩难懂的代码,需要花费大量的精力来理解,提高了其维护成本,对于一个系统来说,影响很可能被持续放大,例如如果程序员无法准确的监控系统,那么系统很可能产生程序员不可理解的行为,这种行为有可能没有意义,或者在特定场合触发bug,甚至可能是导致系统全部失效的bug,进而影响了可用性,又或者一个不可理解的行为导致系统吞吐量,响应时间等可扩展性指标无法提高或者下降。不能预期的行为在系统中是诱发问题的根本所在,因此从长远的角度来看,这三个关键指标中,可维护性是软件在整个生命周期中最应该重视的指标。并且,我们在此断言,系统不可理解的行为通过系统运行的放大作用,终将造成困难。</p>

<h1 id="模型与语言">模型与语言</h1>

<p>任何一个计算机从宏观上来看,其最主要的功能是用于计算与存储数据,对于数据密集型系统,其工作就是存储数据并在多个数据结构之间转换以及传输数据。那么为了支持系统存储数据,就需要特定的数据结构,但是底层的数据结构是面向计算机的,为了给使用者提供统一的心智模型,需要抽象一种人类可以接受的数据结构(尽管底层并非这样存储),这样的面向人类的模型就是数据系统的模型,对于存储系统来说,最基本的操作就是增删改查,以及对模型结构的操作,我们不能提供单一的命令或者API使用户操作特定的功能,为了支持复杂的查询统计功能,我们需要定义一种语言,以便用户更加灵活的操作这样的数据库系统。由此,我们知道,数据库的模型与语言是相互影响的,模型定义了基础的存储结构,语言提供了操作模型的规范,以决定以何种方式转换与传输数据。</p>

<h1 id="表模型与sql">表模型与SQL</h1>

<p>在所有的数据库系统中,表模型是一种通用且成熟的模型,历史悠久的表模型基于行或列的存储,将每一条记录存储为多个字段所代表的一行记录,与人类组织数据最常用的表格非常相似,因此而得名。数据表的模型可以支持各种各样的需求。但并非每一种都很优雅。为了操作表模型,定义了SQL语言(结构化查询语言),其本质是一种结构化命令的语言,数据库通过解析SQL生成执行计划,并以此来操作表模型的方式实现数据库的各项功能。表模型的优点在于 支持各种各样的数据处理形式,无论是查询单表,还是join多张表,一对多,多对一,其存储引擎非常的成熟,抗住很多应用场景的使用,但其本身也是有缺点的,表模型在逻辑上与应用程序的数据模型天生不一致,应用层主要是面向对象,而数据库是表模型,二者操作之间需要对数据进行转换,这是一种代价,在开发设计阶段,为了遵循表设计的范式反而变得麻烦,表设计也算是表模型的一种代价,在使用之前我们需要根据规范设计合理的表结构,这也是一种开发成本,sql的使用上为了得到更高的性能表现,需要对sql的使用进行优化,这也是一种使用成本,总之mysql,PostgreSQL,Oracle等数据提供全能而成熟的表模型时也同样引入了学习,使用,维护上的复杂度。</p>

<h3 id="文档模型与其查询语言">文档模型与其查询语言</h3>

<p>文档模型就是将一条记录组织成json等文本形式的存储模型,其查询语言也是类似json的形式。其优势在于对操作数据性能的提升,以失去表模型对<code>多对多</code> join查询的灵活性为代价。将数据组织成json的好处是,充分的利用数据模型中局部性原理,在查询某一范围相关的数据时可以快速的将数据返回,获得低延迟的查询效果。同时不用考虑严格的表规范,不再存在类似表结构的约束,每一json记录都可以拥有任意字段,非常的灵活多变,以此来应对对数据处理的各种场景。但其缺点也很明显,那就是不太适合数据记录之间有太多关系的场景尤其是<code>多对多</code>等需要大量join查询的场景。同时,无写入时模式不代表其没有模式,其约束会在读取时做检查,对支持的索引类型等进行校验。</p>

<h3 id="图数据模型与graphql">图数据模型与GraphQL</h3>

<p>图模型是另一种极端,图模型也是一种读时模式检查,这意味着写入时不做约束,这一特性让数据模型的建立变得快速而随意,将所有的记录组织成图的表述形式,对于图有三种表述形式,<code>三元组</code>,<code>属性图</code>,<code>超图</code>.目前前两者使用的比较多,将数据组织成,<code>主语</code>,<code>谓词</code>,<code>宾语</code>形式来存储数据,或者组织成<code>节点</code>,<code>关系</code>,<code>属性</code>或<code>节点</code>的方式存储数据。图模型的最大优势就是其对复杂关系的灵活支持,对于关系稠密的数据场景其可以利用图遍历的局部性优势快速的实现各种<code>多对多</code>查询。</p>

<h1 id="数据库的两种类型">数据库的两种类型</h1>

<p>数据处理存在两种类型OLTP与OLAP,分别是在线事务处理与在线分析处理,之所以要从用途的角度如此划分,对两种指标的不同需求,OLTP追求低延迟,用于快速的响应用户的请求,所以适合在线业务使用,OLAP追求的是吞吐量,为用户提供大量数据的离线计算与存储,进而得到分析数据后,给用户使用,事实上数据处理从目标上来说,一种是给用户提供一致的操作(增删改)以及局部的查询,这些都应该一致且快速,而剩下的则是大规模的查询需求,通常需要全表扫描与离线并行计算,通常在数据仓库技术中使用,查询结果通常会计算的很慢,所以衡量的指标应该是磁盘IO的吞吐量而非返回数据的延迟。从本质上正是对数据系统所期望的功能不同,进而考察的指标也会不同,从而产生了数据处理的这两种分类,以后的文章我会分别叙述这二者在实现与设计理念的不不同考量。</p>

<h1 id="数据库如何存储数据">数据库如何存储数据?</h1>

<p>数据库的核心就是持久化的存储数据,持久化的存储依赖于磁盘(依赖内存是否也能持久化呢?),那么将数据写入磁盘,并从磁盘中读取数据就是数据库的核心功能。但,数据库的意义在于高效的存储并支持复杂的查询方式,保证查询关联数据的性能。所以数据库必须做到,支持写入大量数据文件并以多种多样的维度读取文件。那么如何做到呢?以关系型数据库为例,一行记录假如在文件中就是一行字符串,怎么做到快速的插入一行字串呢?磁盘是圆的,通过磁头与磁针的调整进行寻址,寻道。这是磁盘存储数据最耗时的动作,减少耗时且不必要的事情就是性能优化的哲学。因此,我们通过仅追加写文件的方式存储数据就会使写入的性能最高效,因为磁头与磁盘不需要来回的寻道,寻址。但,仅追加的写入文件,那我要是想删除这个文件,或者修改这个文件该怎么办?那就采用版本追加的方式,无论是删除还是修改操作,都仅追加的写入文件一行记录,为数据库创建一个自增的唯一字段,用来表示唯一的数据记录,删除和修改操作都是仅追加到文件但唯一字段相同,然后在读取时从文件尾部开始读取数据,这样一来,匹配唯一标识的第一个记录就是最新的记录值了,但是新的问题是这样的, 存储方式会大量的浪费磁盘空间,文件会越来越大,从而影响查询的性能,因为大部分数据都会是旧版本数据。所以,我们需要定期的对数据文件进行压缩,仅追加文件到一定大小时,就将其复制一份并压缩(去除重复标识的记录),以便节省空间,但是压缩文件的数量又太多怎么办?我们就将其进行合并,定期的按顺序将文件合并成一个大文件,这样一个最简单的原始数据库的存储部分的设计就完成了。
这样一来,我们的写入性能将是最高的,可以说所有主流开源数据库的写入性能都没有这个设计快,但是软件架构的本质就是决策与权衡。这样的设计,读取一行记录需要遍历整个文件,如果读取第一个存储的数据,需要遍历整个文件,查询性能完全不可以接受,因此我们需要继续想一想如何提高读取的性能。</p>

<p>查询是数据库存在的意义,影响我们存储数据的结构有两个因素,一个是占用空间的大小,一个是查询时的响应时间,通常后者更加重要,数据库存储的数据本质上也是文件,如何能快速的找到文件内的某个记录呢?分类是快速找到曾经放置物品的方法,这在计算机中同样适用,为数据记录建立分类,那么分类应该怎么被存储,也就是说每次在添加,删除,更新数据记录的时候都要将分类信息也一同更新吗?这样不会更慢吗?但是,这是值得的,因为在数据库中查询是一等重要的事情。那么这个分类将是什么结构的呢?观察生活中的细节,书中的目录本质上是分级的,也就是树形的结构,那么分类以树作为存储结构应该是最自然的,但树的本质是映射,那么hash映射应该也是可以作为分类的,我们以一个人的身份证id为key,经过散列也可以得到其位置信息,而且查询速度更快。但很显然,hash的形式是没法进行顺序查询的对于要求顺序范围的查询将无能为力。在这里,需要给这个分类数据结构下一个定义,将这种可以帮助我们快速找到数据集的数据结构称之为索引,事实上存储数据库主要工作就是如何维持索引的正确性以及有效性。</p>

<p>使用树作为索引,那使用什么树?从最简单的二叉树说起,我们知道,索引应该被存储在磁盘上,每个节点都应该代表磁盘的一个可寻址的地址信息,索引树的查询效率是与树的高度成正相关的,因为树的高度决定你要在磁盘上进行多少次的寻址操作,而磁盘的寻址是耗时的操作,因此一个优秀的适合磁盘的索引树应该是尽量降低树的高度的树。对于树来说,我们知道删除与添加操作会破坏树的平衡性,使树的查询效率退化,数据库是支持任意删除与添加的,所以索引树应当可以自平衡,AVL还是红黑树?这几种树都是二叉树,树的高度会很高,降低树的高度一定是M叉树,能自平衡的树很显然是B树。B树是一种自平衡的多叉树,将B树充分与磁盘的特性结合,B树的一个节点本质上是一个数组,表示数据记录中的一个索引字段,这个数组的大小恰巧设计成一个磁盘页的大小,因为文件系统读取磁盘时是按页批量读取的,一次IO可以读取一个64KB的磁盘页到内存中。这样64K大小就可以用来存储数据了,然而如果非叶子节点上存在数据记录,那么就会影响这个节点能包含的索引字段的数量,索引字段存储的少了,还是会增高B树的高度,同时会造成数据分布不均匀,使查询的效率变的不稳定。所以,还是需要改进一下B树,进而引入了B+树,我们将数据记录全部存储在B+树的叶子节点上,并且将叶子节点连成一个链表便于进行范围查询,这就实现了sql中的模糊查询,区间查询等功能。这样一来,非叶子节点上全部都是索引字段,那么就可以将树的高度将到最少,同时作为B+树我们还可以,在数据的删除与插入时对其进行自平衡操作,为B+树的每个节点进行分裂与合并操作。</p>

<p>现在我们引入了索引数据,那么在文件结构上如何进行设计呢?假设我们以唯一的标示ID为索引字段,那么如何将索引文件与数据文件相互联系起来呢?这里有两种方式,将索引文件与数据文件合并在一起,这样查询效率是最高的,但缺点是只能有一个索引字段(很显然用主键作为索引,主键就是我们说的数据记录的唯一标识),没办法扩展索引,如果我们要扩展到多个需要索引的字段,那就只能在数据文件之外扩展索引文件,那么B+树的叶子节点存储的是什么呢?存储着主键?这样独立的索引文件会更加节省空间便于扩展,存储着数据记录的磁盘地址吗?那要是地址发生变化更新地址会很麻烦,所以综合来看,存储主键比较合适。上述的两种索引类型即是聚集索引与非聚集索引的区别。</p>

<p>然而,回到最初的设计 如果我们真的使用上述的B+树的索引 那么就意味着我们必须在磁盘上进行随机的读写,幸运的是索引的存在使得随机的写入磁盘不是那么难以接受,上述索引实现方案称之为 原地更新, 与我们上述所说的仅追加写入是有所差别的,这种原地更新文件的实现方案,通常是主流关系型数据库的实现方案,通常适合那些 有大量并发请求,少量写入,多数读取的场合。那么我们最开始设计的数据库,有什么意义呢? 能不能继续利用仅追加的方式实现?如何在保证写入吞吐量的前提下降低读取的延迟?</p>

<p>如果我们可以充分的利用内存的特性就可以做到这一点,所有的写入都可以先写在一个有序的内存结构中,不能是hash表,因为按索引字段维护顺序,内存中维护顺序的适合索引的数据结构有哪些?红黑树?跳表?  这些都是可以的,只要将所有的写入请求全部在内存中存储一份,当内存的数据容量到达一个阈值后,就可以按顺序的 仅追加的写入磁盘文件中,这样的文件称之为SSTable,而这样的内存数据结构称之为LSM树,日志排序归并树,而这种存储引擎的实现方案称之为日志结构更新方案。</p>

<p>但是上述使用内存的LSM+SSTable的方案,如果节点崩溃内存数据没有来得及合并到磁盘文件中,那数据是否就丢失了呢?原地更新的方案也是存在这样的问题,我们还是会在未插入之前就可能崩溃丢失数据,那么有什么办法可以提高数据库的可靠性呢?那就是充分利用可追加文件的特性,我们可以写入记录到来之前立刻,将数据写入一个文件中,这个文件是仅追加的写入,非常的快速(文件系统缓存,磁盘不需要寻址寻道),并且这个文件不需要建立索引,当数据库重新启动的时候我们可以先去读取这个文件内的写入记录,逐条的将记录写入存储引擎中即可,当然如果在写入追加文件中崩溃了那就没办法了,不过经验证明这样的可靠性已经足够,这个仅追加的用于数据恢复的文件称之为VWL,预写日志文件。</p>

<p>综上,我们数据库就设计完了,这样一个简单的描述,就是现代数据库存储引擎的核心理念。</p>

<h1 id="列式存储">列式存储</h1>

<p>列式存储是将一条数据记录的列单独存储在不同的列文件中,所有的列文件以顺序来唯一表示一条完整的记录。列式存储是专门对大量的离线查询进行优化的存储格式,这样做有什么益处?首先,这种存储方式解决了行存储中,列数量过多造成聚合查询时IO操作了太多无用数据。大多数情况下聚合查询仅仅关注记录的一部分,在列存储的数据库中,聚合查询时,只需要将那个单独一列的文件进行读取即可。其次,就是列式存储形式极易适合对某一列单独进行压缩处理,数据一旦被压缩那么就会提高读取一写入的吞吐量</p>

<p>如何压缩?根据记录的特点进行压缩,例如排序的列,并存在重复值,可以使用三元组压缩,(x,y,z), 表示从数值x从第y行到第z行都是x值,如果重复数值多但是没有排序则可以使用位图进行压缩,还可以对位图进一步压缩表示,对于有序且重复不多的列可以将当前数值表示为前一个数值加上一个变化量的形式,然后再对其进行压缩。</p>

<p>列式存储中,文件的形式是每一列单独一个文件,在文件后半部分标示数据字段在文件中的偏移位,这就导致当列式存储的数据库想要写入一条数据记录时需要操作更多的列文件,而且由于严格依赖顺序位置来关联不同的列文件中的列为同一条记录,因此很难建立索引,不过由于列存储数据库通常用于大规模查询的OLAP场景,因此可以将数据的不同备份之间以不同的key进行排序,以此来达到加速查询的目的。</p>

<p>同时,我们还可以使用上文提到的LSM+SSTable的方法实现存储来提高列式存储的写入吞吐量,并利用LSM树的特定对列文件进行排序。</p>

<h1 id="数据系统之间的通信">数据系统之间的通信</h1>

<p>内存中的数据以内存数据结构进行存储,数组,树,堆,map等等 但是将其存储在磁盘上时,往往需要进程转换,显而易见的原因在于,内存中的数据结构都是通过虚拟内存指针相互引用的,对于磁盘毫无意义。因此需要一种技术,可以内存中的数据转换为磁盘中的数据格式,这种技术称之为序列化,同时也需要将磁盘中的数据恢复到内存中,称之为反序列化。 而从更加通用的角度来理解,这种数据格式的转换在各种场景中都是存在的,数据系统之间需要通过网络进行通信,那么就需要将内存中的数据变为适合网络传输的格式,并且接收方可以将其转换回内存结构。 种种场景都需要将数据的格式进行编码与解码,而本篇将主要介绍在数据系统中,如何治理通信的编解码过程中 性能, 可读性, 兼容性 三者之间的矛盾。</p>

<h1 id="编码格式">编码格式</h1>

<h3 id="json-xml">JSON &amp; XML</h3>

<p>编码格式属于一种协议,对于协议最重要的事情就是要被广泛的接受并使用,它才具有意义。在数据系统中真正的被广泛使用的编码格式无疑是人类可读的编码格式,XML与JSON.其流行得益于其良好的可读性以及被各种语言的标准库支持,使其更加流行,进一步降低了其使用成本,而json相较于XML则发挥了其简单实用,更加紧凑的特性,成为互联网最流行的跨语言数据传输格式.每种语言都有其自己的序列化协议,然而饱受诟病的在于其性能的差强人意,以及不支持跨语言的特性,给了json最大的机会.现在,大型的数据系统都需要使用多种语言进行开发,跨语言传输的需求已经成为刚需。
json&amp;xml的劣势也很明显,可读性限制了其性能,数据系统越来越频繁的传输数据,使用json等文本协议解析数据,已经成为一种性能平静瓶颈,进而产生对二进制传输协议的需求。同时,json &amp; xml其文本格式无法对数据控制精度,在一些不允许误差的场景中,并不能继续胜任。</p>

<h3 id="thrift-protobuf-avor">thrift &amp; protobuf &amp; avor</h3>

<p>人们开始追求一种更快的可以控制精度,组织复杂数据格式的序列化协议。
上述三种协议作为一种跨语言的RPC二进制通信协议,其底层支持多种不同的协议,但作为二进制协议,通常表现上都是通过IDL定义一套模式,然后生成多种语言的代码库,进而被嵌入程序中使用,这是一种简单的使用方式。</p>

<p>thrift与protobuf是相似的,通过IDL定义模式,生成不同的代码库嵌入不同的语言中,编码方式上,都是需要一个标签字段作为唯一标示,不使用用名字的原因是保证顺序且与业务无关,这样一来就可以做到在整个版本演进的过程不会有改变标签字段的需求,仅可以删除(尽量不要删除)或者添加。同时,对于每个字段都可以有选项指定其是必须的还是可选的亦或者存在默认值,如果想在今后的版本迭代中在客户端与服务端不能保证版本一致的情况下继续使用,那么最好将字段变为可选并存在默认值的,这样一来旧的客户端就可以对没有读取到的实际上已经被删除的字段填充默认值</p>

<p>作为二进制协议,传输的肯定是字节流,对于字节流想要将信息还原为原来的形式,解码的一端需要知道数据字段的长度,类型,以及字段的值等信息,否则没有办法将其序列化回原来的样子。所以我们需要将其传输过去,字段名称呢?并不需要只需要传递标签即可,这是为了保证兼容性以及使字节流更加紧凑的权衡设计。</p>

<p>那这种方式如何保证兼容性呢?兼容性分为向前兼容与向后兼容,向后兼容指的是读取的一端是最新版本而写入数据的一端为旧版本,那么新版本一定知道旧版本中的模式定义,因此很容易做到兼容,只需要保留之前的标签字段,保证一个标签号没有使用过即可。新版本的读取端会将其已经删除的字段与新填入的字段赋予默认值,若为可选字段的话。</p>

<p>向后兼容指的是读取一端为旧版本,写入一端为新版本,旧版本需要预知新版本的模式,这也很容易通过标签号与选项实现,只要保证旧版本读取到未知的字段时自动忽略即可,而那些在新版本中删除的字段填充默认值即可,但倘若选择必填字段的选项,则会破坏兼容性,通常封装的框架会报错提示。
但avor的设计却是不同的,其是hadoop的子项目,用于在大规模的传输数据的一种二进制协议。他有什么特点呢?其协议中没有所谓的字段标签号,类型,名称,长度,选项等信息,只有纯净的字段值组成的二进制流,这是已知所有二进制协议中编码最紧凑的协议。那他是如何保证正确的被解码呢?</p>

<p>TCP在通信前通过三次握手确定关系,avor在一次通信中,先彼此交换一个数据包,数据包中包含读模式与写模式. 模式结构中包含,将要发送数据的格式信息,比如字段的名称,由于采用这种策略,avor没有使用字段标签编号,而是直接以字段名称作为标识,同时还有字段长度,类型等信息。</p>

<p>那它是如何保证向前|后的兼容性呢? 读模式与写模式不必相同,当读模式更加新的时候,删除与添加的新字段会被赋予默认值或忽略。写模式更新的时候,则正好相反,依次达到相互兼容的目标。
相较于thirft与protobuf的优势就是其不必在每次发送数据中包含格式信息,并且不必使用标签号,这样就会对发送数据的顺序不做要求,同时可以动态的更新。其劣势在于需要维护读写模式的版本状态,适合大规模的发送相同格式的数据。</p>

<h1 id="数据流模式">数据流模式</h1>

<p>所谓数据流模式,即是一种数据系统相互通信的方式,通常来说普遍的通信方式有四种 读写数据库,RestAPI,RPC,消息传递</p>

<p>从应用程序中写入数据,到应用程序读取数据,作为数据库这其中可能间隔了很长时间,一旦在这个过程中数据库的模式发生了变化,添加,修改或者删除了字段,旧版本的应用程序必须兼容,当然更新应用程序也是可以的,然后总是存在不能及时更新的情况。同时,在读写数据库的过程中,数据在内存中的表现形式会发生变化,被转换成应用程序关心的模型,这本质上是一种浪费,这个动作不能带来实质性的收益。
RestAPI 使用http的协议,遵循一定规范而设计的应用程序与应用程序之间的通信方式。其特点是利用json等文本序列化协议通信,其特性就是可读性高,易于调试,但对性能有所损耗,并且对数据的类型精度的控制不足。然而,快速的开发速度与可读性高的需要大多数情况下是值得用性能交换的。
RPC 远程过程调用,让应用程序像调用本地方法一样调用其他应用的接口,然而这是现实的,本地函数只有成功与失败两种状态,而远程过程调用却存在着,成功,失败,超时三种状态,反而是复杂度变高。但其本身,可使用二进制协议传输,因此其具备二进制协议的高效特性。
消息传递,通常使用消息队列实现两个应用程序之间异步的传递消息,通常适用于不需要应答且可异步处理的请求,使用消息队列的好处是可以保证消息恰好一次被消费的语义,并异步的,可缓冲的发送请求,可以使消费者不至于被大量请求压跨。</p>

<h1 id="数据的复制">数据的复制</h1>

<p>当单一的服务无法应对负载压力时,我们可以使用共享架构,进行垂直扩展,也就是换内存更大,磁盘更多,CPU处理能力更强的机器,机器的内存与磁盘都是多个线程共享使用的.这是一种简单的策略,服务通常无需改动,但硬件设备性能提升一倍,其成本不只是提高一倍。往往因为其成本过于高昂,无法选择这样的方案。那么我们就需要使用多台相同硬件配置的机器,来进行扩展,也就是无共享架构,通过使用多台机器不相通的内存与磁盘,进程之间通过网络进行通信数据交换,获得了极高的扩展性,同时兼顾了成本的增加,这种无共享架构组成的系统就称之为分布式数据系统。 数据复制的意义在于,提高数据系统的可用性与可扩展性,我们通过将数据复制一份的方式进行备份以提高可用性,用备份数据分担流量以提高扩展性。 当单台机器的磁盘容量不足时,在分布式数据系统中,通过分区技术解决,将数据集合分成不同的子集合,分散在不同的机器上,提高存储容量的同时也会时各种操作变得更加复杂,但却解决了单机存储空间有限的问题,同时分散的数据也有助于分散负载压力,分担流量的好处是大大的降低了响应延迟。</p>

<h1 id="主从复制">主从复制</h1>

<p>对于两个进程节点,通常指定一个为主节点,负责所有的写入与部分的读取,另一个节点为从节点,用来根据主节点发送过来的变更消息,更新自己的数据集,并提供读取请求,因此主从复制可以除了可以冗余数据提高可用性外,也可以通过不断的增加从节点来提高系统的扩展性,需要注意的是往往主节点只有一个,也就是写请求无法得道到扩展,同时对于复制的方式也有两种选项,同步复制与异步复制,顾名思义,当主节点写入数据后,等待从节点写入成功的通知的复制方式为同步复制,无需等待通知的方式为异步复制,同步的好处是可以保证副本数据是最新的,进而保证读取副本信息的及时性,但坏处就是对整个系统的可用性造成影响,假设同步多个从节点,如果有一个节点因为自身或者网络问题无法通知主节点复制完成,那么整个系统就会无法工作。而异步复制虽然无法保证从节点的副本数据是最及时的,但却可以提供系统的可用性,并提供整个系统写入的吞吐量。
如何想主从复制的集群中添加一个副本呢? 添加副本并不是简单的复制,如果停掉整个集群,然后从主节点复制数据那会很容易,但这是不可接受的损失,如何</p>

<p>保证在不停机的情况下添加一个新的副本呢?通常的做法是,从主节点快速生成一个快照并记住这个时间点,然后利用这个快照启动一个新的副本节点,之后将主节点在快照生成后的所有变更日志以流的形式应用到副本节点上,这样才能保证副本的数据一致性。</p>

<p>那么如何下线失效节点呢?有各种问题会是节点失效,如果是副本节点,那直接下线即可,重启时应用变更日志即可.但是如果是主节点呢?主节点需要接受写入的请求,一旦下线需要通知客户端变更写入请求的服务地址,并且还需要从集群的副本节点中选择一个作为主节点,选择谁呢?可以手动配置也可以通过共识算法选举,主节点的数据切换将会有数据冲突,丢失的风险,甚至是主节点伪崩溃在选举新的节点后又重新回来,造成多个主节点的脑裂现象。这些问题将在之后一一解答。</p>

<p>日志的复制是如何实现的呢?通常有三种方法,基于sql语句的复制,将日志中的sql语句按顺序再次执行一遍,这样的好处是sql语句进行复制较为简单,mysql1.5之前都使用这种方式,然而致命的是,如果我们的sql语句中包含不确定的部分,那么一致的复制将得不到保证,例如我们的sql中包含now()函数那该怎么处理呢?通常需要结合其他的复制实现方案,例如直接基于wal日志,基于二进制的复制好处是不需要像sql经过语法分析生成执行计划,消除了sql函数中的随机性,然而坏处是可读性降低,预写日志对数据库的版本兼容性有所要求,这给集群的扩展性与升级上造成了影响。目前,将二者结合使用比较流行,当sql中出现不确定的函数时将使用二进制传输,但这并不是完美的解决方案, 我们期望可以跨不同类型数据库的进行数据复制,与底层实现无关的复制协议,也就是说我们可以根据业务定义逻辑日志,这种逻辑日志跟数据库底层实现无关,每种数据库按照约定自行解析逻辑日志的内容,并应用于存储引擎,引入逻辑日志的设计,可以较好的解决上述问题。</p>

<p>数据的同步只要基于网络,那么就一定会存在网络延迟,所以主从复制的过程中必须解决复制过程中不可控的延迟因素对系统可用性与一致性的影响。</p>

<p><strong>读写一致性</strong> 当用户在写入数据后,立刻要读取写入的数据时,采用主从复制的系统,将会面对着这样的问题,由于在主节点写入了数据,但立即的读请求却在从节点读取,如果是同步复制(但会延长用户的响应时间,通常不会使用) ,延迟较低不会太过明显,但如果使用异步复制 那么数据究竟在何时才会被真正写入从节点是不可控的,那么当用户立即的读请求被恰好分配给这个延迟的从节点,将会读不到其写入的数据。有什么办法可以解决这样的问题呢?  如果修改的数据仅仅是这个用户修改的,那么我们可以将写入后的同一个用的读取操作交由主节点完成,这样也不会造成太大的负载,这样会让用户立即看到其写入生效,但其他用户对这个数据的读取允许存在一些延迟,是可以的。第二种办法是动态的识别从节点数据的延迟情况,从延迟最低的节点进行读取。 第三种方法是通过逻辑版本号的方式,客户端请求时传递一个逻辑的版本号,服务端保证返回此版本号之后有效的数据,如果请求的节点没有有效数据,则交由其他节点完成。当存在跨多个数据中心进行主从同步的场景,读写一致性的问题会非常的明显。更加复杂的情况是用户在多设备上进行操作时,由于切换了网络,路由路径发生了改变,必须保证通过一个用户的请求落在同一个数据中心上,并且不能依靠逻辑时间戳等版本号信息,可以通过对用户ID进行唯一的hash散列,使其落在同一个数据中心内,简单的方法是,保证写入操作的用户从主节点立即读取到写入的数据,而让其他用户存在一些延迟的读取。</p>

<p><strong>单调读</strong> 当用户读取数据时,保证其不会读取到历史数据,这样的一致性保证就是单调读。其成因为 用户在主节点写入数据,在一个滞后较短的节点读取数据,紧接着又在一个滞后很长的节点读取数据,那么用户可能读取到一个比之前更老的值.解决的办法就是给用户id散列,保证一个用户每次都访问相同的副本。</p>

<p><strong>因果一致性</strong> 当用户连续的写入一些有关联的数据时,这些数据也要保证按写入的顺序读取。 例如第一条写入是一句问题,第二条是一句回答,两条记录是有因果依赖的.那么其他人在读取这两天记录时也应该先读取到问题在读取到答案。否则就会造成逻辑混乱, 保证因果一致性的方法在单机数据库中可以通过事物很好的保证,但在分布式系统中由于复制与分区的存在,尤其是分区的存在使的数据没有了全局的顺序,并且分布式数据库为了保证效率通常不完全的支持事物特性.导致分布式数据支持因果一致性的困难。直接的解决方案是,将因果依赖的数据划分到同一个分区之中.但这样会影响效率,不能做到跟据数据的特性进行分区,另一种做法是参照Linux对并发指令执行的顺序保证策略,先行发生原则,稍后会详细讨论。</p>

<h1 id="多主复制">多主复制</h1>

<p>主从复制的一大缺点就是,无法对写入请求进行水平扩展,所有的写请求都必须在同一台机器上完成,这样就会产生单点故障,当某段时间主节点存在网络抖动,而失效时所有的写入数据都将失效。那么,支持多个主节点的复制方式将变得非常诱人,但其难度将大大增高,所谓多主复制就是,写入请求可以负载到多个主节点上,每个写入请求写入一个主节点后,由其同步给其他主节点,也就是说每个主节点同时也是其他主节点的从节点。这样从架构上将完全的将读写请求水平扩展,但其实现难度却非常高,其本质上是因为我们在同一时刻,无法确定哪个节点副本上的数据是最新最完整的数据。</p>

<p>多主复制拥有其适用场景,例如为了提升机房级别容错性或者就近访问,使用多个数据中心,如果还是采用主从复制模型,那么对于写请求将失去意义,因为所有的写还是要请求主节点所在的数据中心,而使用多主复制模型,仅将写请求发送给最近的数据中新,然后同步的写入其主节点,之后在异步的同步到其他的数据中心主节点即可,但由于多数据中心之间较大的网络延迟以及存在写入冲突等问题,使得多主复制充满挑战。同时具有离线客户端操作的系统也可以看作网络可以无限延迟的多主复制问题,还有基于多人在线编辑面临的多主复制之间的写入冲突问题。</p>

<p>对于多主复制模型,如何解决写入冲突成为最大的挑战?最简单有效的做法就是避免冲突,将用户路由到一个确定的数据中心,所有的写操作都是有指定的主节点完成,对于用户来说他们像是使用主从模式。然而这种方案的弊端在于过于依赖用户与数据中心的相对位置,当数据中心迁移时,或者用户漫游到其他位置时,离之前的数据中心很远,这种方案将失去意义。其次,我们必须要保证所有的主节点允许出现短暂的不一致,但最终会收敛于相同的值,这可以使用时间戳或者版本号来确定写入的逻辑顺序,最终只能有一个写入请求胜利。这样做法简单但却会丢失数据,如果想不丢失数据,可以选择规定数据的格式,然后将数据进行合并,保留所有的数据。或者同时用户存在写入冲突,由用户处理冲突(git就是这样解决的)</p>

<p>对于多主复制来说,网络拓扑结构由三种,环形,星形,全部复制型。环形与星形都容易出现单点故障,使整个集群不可用,而全部复制型对网络压力较大,同时不好保证因果一致性,例如当像A节点写入数据后,在B节点进行更新,但由于网络问题,A的写入操作没有及时的复制到B节点,B节点则认为客户端更新一个不存在的记录.保证这种因果一致性的方法称之为版本向量,稍后会介绍,同时多主复制还要避免循环复制问题,当记录被复制时如何保证同一个节点接受了两次复制?通常对每个集群中的节点进行编号,复制的请求携带已经完成复制的编号信息,一旦节点检测到自己的编号则忽略复制请求。</p>

<h1 id="无主复制">无主复制</h1>

<p>之前讨论过的都是所有的写入请求集中在某些节点上,当这些节点不可用时就需要进行切换来保证集群可用。但在复制模型上还是存在另一种实现,无主复制模型,所有节点都对等存在同时接收写入与读取请求。这就给保证复制的一致性造成了新的挑战,客户端到底应该从哪个节点进行读取与写入?通常有两种做法,客户端同时写入多个节点,当半数以上返回成功即可,然后读取时也是从多个节点读取并选择版本最新的数据 另一种做法是使用一个协调者节点客户端与其交互,协调者节点不负责任何的写入与读取而是进行转发,不同的是协调者不会维护写入的顺序。</p>

<p>那么对于多主复制,失效的节点在恢复后,如何能修复中间错过的写入请求呢?</p>

<p>一种做法是,使用读修复,即在读取数据时,读取多个副本的数据,然后检测到最新版本的数据,并用最新版本的数据复制给其他副本上,在读数据时修复副本的不一致,但明显的弊端是对性能的影响。另一种方案称之为反熵,启动一个后台线程不断的校验各个版本的正确性,然后将其修复。但这有时并不及时,同时也无法保证顺序一致性。</p>

<h3 id="法定人数quorum">法定人数Quorum</h3>

<p>在分布式系统中,如何确定一个写入或者读取是成功的呢?需要全部的副本节点返回结果才可以吗?有没有更加高效的做法呢?我们知道,当读取的节点数为r,写入的节点数为w,而集群实际上的节点数为n时,当w+r&gt;n 成立时,则 n&gt;w时,则允许有n-w个节点写入失败,当n&gt;r时,则允许有n-r个读取节点失败,这样读与写就可以以小于集群节点总数的代价进行读写操作。
Quorum 并不是完美的,当发生一些边界情况时,依旧会读取到旧值,例如写后立即读取,写入的请求还没有及时的同步给足够的w数量的副本上,我们就要从r个副本上读取,那么这会存在读取到旧值的情况。例如,写入w个副本中,但其中却有写入失败的情况,使其w的值小于设定值,那么也会有可能读取到旧值。同时,Quorum也无法保证上面对一致性的种种要求,他仅能在正确工作的前提下保证最终一致性,而想要保证其正确工作就需要共识算法与分布式事务的支持。</p>

<h2 id="多副本的并发写入冲突问题">多副本的并发写入冲突问题</h2>

<p>我们需要先定义一下什么叫做并发操作,所谓并发指的是两个操作相互不依赖彼此,并不知道彼此的存在这样的操作可以称之为并发操作,其谁先执行谁后执行,或者同时执行都是允许的,相对的有依赖性的操作,也就是说两个操作之间存在因果关系,B操作必须依赖A操作先执行,如果二者的执行顺序不一致将会造成混乱,这样的操作称之为非并发的,线性操作。</p>

<p>现在有这样的一种问题,A客户端与B客户端同时写入5个副本中,A客户端并不知道B客户端的存在,成功的写入了三个副本<code>1,1,1</code>,B客户端也写入相同主键的三个相同副本中<code>2,2,2</code>,但由于网络延迟其中两个副本A客户端的写入后与于客户端的写入到达,则最终写入的是<code>2,1,2</code>,破坏了法定人数的条件。</p>

<p>为了解决并发写入这样的问题,我们需要引入并发写入冲突的解决方案,最简单的方案就是以时间戳来判断,将最后写入的请求保留,其他的并发写入被丢弃,这种做法的优点在于非常的简单,但是确定也很明显,那就是多台机器的时间戳并不统一,而且多个副本间同步就会出现上述的问题。</p>

<p>更近一步,我们需要保留并发写入操作的不同版本,为每一个写入相同主键的操作分配一个唯一自增的版本号,当第一次写入时,我们不进行任何并发检测,而是直接分配版本号,并记录写入的值,当第二次写入时,需要写入上次的版本号信息,当版本号信息于数据库当前的版本号信息比较,发现较老时,说明这期间存在了并发操作的执行,这时只需要简单的将比该次操作版本低的值进行合并覆盖(将之前版本的数据与该次请求合并),保留比其版本高的值。
进一步进行扩展到多副本场景,对于每一个主键我们需要一个版本号,那么多个副本中相同的主键,我们就需要维护一个版本号向量,通过这个向量来维护多版本的并发写入。</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>觉有情 </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://logikoisto.github.io/2019/ddia/>https://logikoisto.github.io/2019/ddia/</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://logikoisto.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/">
                    #架构设计</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://logikoisto.github.io/">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://logikoisto.github.io/2019/linked_list/" class="prev" rel="prev" title="算法训练-链表问题"><i class="iconfont icon-left"></i>&nbsp;算法训练-链表问题</a>
         
        
        <a href="https://logikoisto.github.io/2019/useless/" class="next" rel="next" title="我为什么叫无用">我为什么叫无用&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2014 - 2020</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://logikoisto.github.io/">觉有情</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>












    
    
    <script src="/js/vendor_no_gallery.min.js" async=""></script>
    
  



     </div>
  </body>
</html>
